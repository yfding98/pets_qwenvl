services:
  vllm-qwen_vl:
    container_name: vllm-qwen_vl
    image: registry.mthreads.com/mcconline/vllm-musa-qy2-py310:v0.7.3
    privileged: true
    ipc: host
    shm_size: "80gb"
    working_dir: /workspace`
    entrypoint: []
    environment:
      - MTHREADS_VISIBLE_DEVICES=all
    volumes:
      - /data/models:/models
    command:
      - /bin/bash
      - -c
      - |        
#        python3 -m vllm.entrypoints.openai.api_server \
#          --model /models/Qwen2.5-VL-72B-Instruct/ \
#          --served-model-name qwq-32b \
#          --trust-remote-code \
#          --tensor-parallel-size 8 \
#          -pp 1 \
#          --block-size 64 \
#          --max-model-len 2048 \
#          --max-num-seqs 128 \
#          --device musa \
#          --port 8000 || tail -f /dev/null
    ports:
      - "8020:8000"
    networks:
      - ragflow
